use leptos::*;
use serde::{Deserialize, Serialize};

#[derive(Serialize, Deserialize, Debug, Clone)]
struct PostMetadata {
  title: String,
  description: String,
}

impl PostMetadata {
  #[cfg(any(feature = "ssr", feature = "rust-analyzer"))]
  fn parse(content: &str) -> Option<(PostMetadata, String)> {
    use gray_matter::engine::YAML;
    use gray_matter::Matter;
    let matter = Matter::<YAML>::new();
    // TODO: fork gray_matter and write a version where the returned
    // content is a &str.
    let data = matter.parse_with_struct::<PostMetadata>(content)?;
    Some((data.data, data.content))
  }
}

/// This is the raw html generated by the markdown parser.
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct PostContent(String);

impl PostContent {
  pub fn inner_html(self) -> String {
    let PostContent(html) = self;
    html
  }

  #[cfg(any(feature = "ssr", feature = "rust-analyzer"))]
  fn parse(content: &str) -> Option<PostContent> {
    use pulldown_cmark::{html, Options, Parser};

    let mut options = Options::empty();
    options.insert(Options::ENABLE_HEADING_ATTRIBUTES);

    // In the future I want to do a bunch of customization of the created
    // css.
    let parser = Parser::new_ext(content, options);
    let mut html_output = String::new();
    // TODO: figure out if there are possible errors
    html::push_html(&mut html_output, parser);

    Some(PostContent(html_output))
  }
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct Post {
  pub title: String,
  pub link_slug: String,
  pub description: String,
  pub content: PostContent,
}

impl Post {
  #[cfg(any(feature = "ssr", feature = "rust-analyzer"))]
  pub fn parse(slug: String, content: &str) -> Option<Post> {
    let (meta, rest) = PostMetadata::parse(content)?;
    let content = PostContent::parse(&rest)?;
    Some(Post {
      title: meta.title,
      link_slug: slug,
      description: meta.description,
      content,
    })
  }

  pub fn create_href(&self) -> String {
    format!("/blog/{}", &self.link_slug)
  }

  #[cfg(any(feature = "ssr", feature = "rust-analyzer"))]
  pub async fn parse_from<P: AsRef<async_std::path::Path>>(path: P) -> Result<Post, ServerFnError> {
    use async_std::fs::read_to_string;
    use ServerFnError::ServerError;
    let content = read_to_string(&path).await?;
    let slug: String = path.as_ref().file_stem()
      .and_then(|s| s.to_str())
      .ok_or(ServerError(format!("Could not parse slug from {:?}", path.as_ref())))?
      .to_owned();
    Post::parse(slug, &content).ok_or(ServerError(
      "could not parse post".to_owned(),
    ))
  }

  #[cfg(any(feature = "ssr", feature = "rust-analyzer"))]
  pub async fn parse_in_dir<P: AsRef<async_std::path::Path>>(
    path: P,
  ) -> Result<Vec<Post>, ServerFnError> {
    use async_std::fs::read_dir;
    use futures::future::try_join_all;
    use futures::stream::{StreamExt, TryStreamExt};
    read_dir(path)
      .await?
      .map_err(|err| err.into())
      .and_then(|entry| async move { Post::parse_from(entry.path()).await })
      .try_collect()
      .await
  }
}

// TODO: build an api that only gets the metadata for each post?
// Also, I should cache a map of posts to use server side?
// Except really that's just what's used when generating. So I'm
// not sure there's a need. But good to learn.

#[server(GetPosts, "/api")]
pub async fn get_posts() -> Result<Vec<Post>, ServerFnError> {
  Post::parse_in_dir("posts").await
}

#[server(GetPost, "/api")]
pub async fn get_post(link_slug: String) -> Result<Post, ServerFnError> {
  let path = format!("posts/{}.md", link_slug);
  Post::parse_from(path).await
}
